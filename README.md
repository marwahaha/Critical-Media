# Critical-Media
A position statement on contemporary media arts education

What are the responsibilities of educators today when it comes to media arts education? How can we engage in ethical discussions about using tools that are, by many accounts, actively destroying our planet, pulling apart the social foundations of communities, and advancing capitalist concerns over human ones?

In the last decade, there has been an explosion of STEM and STEAM educational initiatives in the United States, pushing students towards degrees in Scien, Technology, Engineering and Math. RISD tacked on the A (for Arts) in an attempt to “… foster the true innovation that comes with combining the mind of a scientist or technologist with that of an artist or designer.” And this is fine, but what’s missing here is the lack of a context when education these students. The models they are being shown are Silicon Valley tech companies; “disruptors” who are really helping maintain the status quo.

Part of this growth around these forms of education is also making it more engaging to the students. The act of ‘making’ is not integral to the idea of education. And hands-on work clearly reinforces the act of learning, but it’s just technical skills until it is applied to something beyond.

If Art is to hop on this bandwagon, it should do so not as means of injecting design into an engineering context, but as a way of engaging communities and individuals in a meaningful way. It’s easy to use a newly accessible technology in a project, but that doesn’t amount to anything more than technical mastery of a tool. In this regard, hitching the Arts to the STEAM bandwagon reduces the Arts to a trade that is not based in human values, which causes students to ask the easier question of “how” instead of “why”. 

Access to these systems of computational media provide an explicit and implied power; power over the physical infrastructure, power over the people who rely and use it, power over the services that the media operates upon, power over who and what has access. Access is typically tied to socio-economic power, but can be attained through other means. It is not an all-or nothing proposition, there are varying levels of access. One can have access to computational media through a cellular phone, in a browser’s console, a shared computer terminal in a library, or through the might of a multi-national company supporting the execution of your code. The level of access an transform the nature of how one interacts with the media.

Formal and informal education, alongside exposure, are structured means of access that can provide communities and individuals power that is best expressed through computation. Different forms of education should be dependent on the community that is working with the tools. The systems should be tailored to meet their needs, not a generalized system. Generalized systems produce an imbalance, in which the bodies that formalized the educational materials see their power expressed through the tools. It becomes a homogenized network. This standardization privileges those in power, and the one who can best parrot the structures in place.

Here present projects that engage these tools in a way that push beyond the mere teaching of the tool, and offer some indication of how, as media art educators, we can start to build a new skill set for our students that challenges them in ways the foster engagement with community, and push against prevailing norms in technology adjacent communication.

## Exposing Algorithms 
Algorithms rule our social interactions when communication is mediated by machines. Facebook, Twitter, Instagram, and Gmail decide what gets seen, who is promoted, and was language is used in ur conversations. This is sometimes done with explicit results, like Facebook and Instagram barring nudity, and other times with suggestions like Gmail’s automatically generated “quick responses”. Posts are promoted by engagement and popularity. If there’s something disagreeable but not banned, it worms its way into the public space because people will react to the content.

Contemporary media art is nothing if not algorithmic in nature. Mainstays of the software art scene like Casey Reas are very much *all about the algos*. Engagement with an algorithm is one of the fundamental aspects of working with contemporary media, particularly when dealing with interactive work which has an input, algorithmic process, and output. Learning how to create an algorithm is important, but also understanding how algorithms come to understand the world and have embedded bias is also important.

As noted in (Big Data answer is the answer), there is an implicit trust of algorithmic processes. It is easy to cede decisions to these tools for a variety of reasons. For starters, there’s the appearance of neutrality. If it’s on a computer, it must be objective! The flaw in this assumption (identified in the next section around infrastructure) is that these are made by people, and imperfect as we are.

Teaching algorithms can be fun, it makes for pretty pictures! It also makes for prediction and analysis that can sometimes be interesting. Acknowledging that technology is not good, bad, or neutral, we can also see that there is something that can be learned by evaluating how these tools work. 

The work of Adam Harvey, particularly his CV Dazzle (https://ahprojects.com/cvdazzle/) and  Hyperface (https://ahprojects.com/hyperface/) projects,  which leverage computer vision algorithms in various ways, exposing their weaknesses and biases.   

CV Dazzle and Hyperface are designed to thwart computer vision libraries from finding faces computationally. The projects exploit the algorithms by moving above and below the thresholds the computers are looking for. While this exposes the functionality of the tools, it also opens up broader questions about privacy, surveillance, and analysis. CV Dazzle achieves this through makeup and hairstyling to make a face appear less than human. Hyperface does this by creating multiple false positives, overloading the system with false faces. This exploit leverages the expectations of the algorithm to negate its effectiveness.

Here, it’s apparent that knowledge of the algorithm is not used for a mirror, or goofy snapchat-style filters, but rather for identifying the means though which we can subvert expectations on how the machine works. Knowing the tools is a starting point, but knowing their limitations can be an excellent way to demonstrate how to break these things.

## Infrastructure exploration
“One person’s infrastructure is another’s job”
Our technological toolchain is made up of deep time, coming from the earth’s core, manifesting as materials we dig up and put into batteries, comprised of shipping lanes and data packets that help plan the movement of freight shipments across the world. Knowing the basics of electronics and sensors is a good place to begin here. 

A microcontroller is not just a small computer on a chip, it is the sum evolution of strip mining, cryptography and war, and the never-ending just to make faster computational tools. The evolution of these from specialty devices designed for rocket guidance systems to moving to  art based platforms should not be covered up or obscured. It’s through these trees of media’s history that we can understand the present. 

Embedded systems like microcontrollers which enable the “internet of things” have also given rise to the network as a metaphor for how to understand and talk about these tools. In part, this is because computational devices tend to not operate isolated from each other. They are connected through infrastructure, the physical systems that enable them to act upon other forms of media. The network metaphor offers us a way to talk about these immaterial operations and potentially executable symbols as something that lives alongside the physical infrastructure. This metaphor, coupled with physical points of access, offer potential moments of exposure to the increasingly baroque systems of operation that support computation. 

The current plague of internet connected devices is enabled by both the physical proliferation of financially inexpensive devices and “the cloud”; the nebulous entity that stores our information and retrieves our movie suggestions. Embedded devices like the ESP8266 provide easy access to internet and network systems, with the ability to explore and play with infrastructures local and global. Identifying the ways in which these infrastructures engender, consolidate and expand existing power structures can happen here.

Evan Roth’s Red Lines (http://p2p.redlines.network/) documents the points where undersea fiber optics lines come on shore. These locations mark places where boundaries are crossed and act as a physical reminder of the infrastructures that carry information around the world. The naming refers to its eh infrared light that transmits data as quickly as possible, but also harkens back to the red lines maps that illustrated telegraph cables laid by the British empire to its various military outposts. the paths the cables flow are the same. We reinforce existing structures as we add new layers to them. this reinforces power structures and illustrates the homogenization offered by digital technologies.

## big data/machine learning
The network metaphor is also useful in that it reveals the interconnectedness of these systems. Computational media’s core differentiator, the executability of it, requires multiple agents to become manifest. Traditional media was a consumption model, something was made by an agent, then consumed by anther. With computational media, the dynamics between the two is shifting. Computational media relies on humans as a resource for consumption, but also for interaction and information. The capacity of computational media changes and grows with accumulated data, power, resources, and research into its capabilities. Humanity is now a resource for the media itself; pressing buttons to reconfigure the systems while providing the content that feed the machine. The massive accumulation of data that is driving what we call “machine learning” is fully transforming humanity into a resource for computational media. 

We train google’s autonomous car efforts with reCaptchas, identifying buses, bicycles, traffic lights and signs. We contribute to voice recognition with amazon echoes, google homes and apple’s siri. these then retrain us based on the data they have received, moving towards a homogenized and staid environment, where all information is a generality brought forth through an algorithim trained on our behaviors where we try to please the machine to make t happy.

Sam Lavigne’s training poses (http://lav.io/training/) uses Microsofts Common Objects in Context (COCO). COCO is a training dataset with hundreds of thousands of images from Flickr tagged by amazon mechanical turk workers used to identify common objects in complex scenes. Lavigne randomly selected an image with a human subject, and attempted to match his pose to the pose identified in the system. When he was successful in approximating the pose, his photo is superimposed on top of the original image.

With tags like “A person is doing something very interesting” and “a person sitting down playing drums wearing a tie”, the humorous poses struck by Lavigne reinforce the absurdity of adapting our behaviors to those the dictated by machines. 

## data and access
The tools above all rely on information. this data can also be used as a tool for research and journalism, but also to identify other areas of media that needs to be addressed. new institutions like data and society and the ai now institute, alongside existing orgs like propublica, are finding new ways to engage in critical media through data journalism. taking the tools of the big data sets in silicon valley, these places are identifying potential bas in information through examination of public records, and platforms.

These social endeavors move beyond the “intersection of art an technology” and start to raise an awareness of community based and led research into the implications of contemporary technologies. 

Mimi Onuoha’s writings on ‘algorithmic violence’ (https://github.com/MimiOnuoha/On-Algorithmic-Violence) identify ways in which unequal access to information and computation reinforce the status quo, paving a path for hyper capitalism to continue unabated, predictive policing to mobilize forces against the least able to defend themselves, and users who are eliminated from platforms because they do not conform the the rules.

This extends beyond the screen into the fabric of our lives, as we have integrated digital tools into all parts of our lives, these have the potential to raise us up or pull us down. thee are not outliers, but the reality for many. Engaging in these areas, extending from data visualization to this is a way to make these tools if not avaiable, at least understandable to all.

Generally we need to acknowledge that the tools we're using are generated from a top-down approach. We need to build bottom-up methods of working with contemporary tecnhologies. OSes, platforms, etc. are build with expanding the interets of the elites, not of the communities and individuals who use thm. By working with the people directly this will help make tools better for all.

There’s a reason this is being posted on github, where the text is available for anyone to fork and adapt to, add upon, or change. That access, the transparency is aspirational, but it’s a pace to start.
