# Critical-Media
A position statement on contemporary media arts education

What are the responsibilities for educators today when it comes to media arts education? How can we engage in ethical discussions about using tools that are, by many accounts, actively destroying our planet, pulling apart the social foundations of communities, and advancing capitalist concerns over human ones? How can we balance the practical needs of students (like securing employment) with the aspirational needs we have for them (becoming engaged citizens)? [1](#1)

This is in part a response to the explosion of 'maker' culture, and the emphasis on STEM and STEAM educational initiatives. Students are getting their heads filled with a whole bunch of 'disruption' nonsense, but it's reinforcing the staus quo of Silicon Valley culture, which is problematic for a variety of reasons.[2](#2)

For these purposes, contemporary media art will be discussed along the folloing four axes :  
* algorithims
* infrastructure
* interaction/machine learning
* access/data

## 
There are mutiple paths that are available to us as educators, and one of the best things we can do is get our students to question some of the general presumptions surrounding technoogy itself. In my program [3](#3) we have an issue that I've seen elsewhere, the attraction to the next new shiny object. The fad for VR has just abtu peaked, and there's going to be a new attraction emerging on the horizion (blockchain in the classroom isn't that far off). And while it's good to have exposure to these, in the rush to play with the tools, a critical inquiry is generally missing. We are all really good at answering "what" and "how", but the "why" is often left lacking.

This is manifest in the easy trappings of stories around technical utopias or dystopias, or that technology wil be our savior. These are easy things to address because they don;t ask us to examine what it means to be human. It asks how a tool works, not how a tools works in relation to a person, or an individual. Being truly human is hard. The mirror these tools provide us with shoudlnt obscure that fact. Usually they help point it out really well, but we misplace the locus of where we can act, and how the tool at hand enhances or diminishes some human attribute. [4](#4)

As I indicated above, technoogical literacy is important, not only so our students can survive in a career once they've graduated, but also so  they can articulate and critique the systems they are using. There's no substitute for first hand knowledge. In this regard, basic programming and electronic skills are super helpful.

Access to these systems of computational media provide an explicit and implied power; power over the physical infrastructure, power over the people who rely and use it, power over the services that the media operates upon, power over who and what has access. Access is typically tied to socio-economic power, but can be attained through other means. It is not an all-or nothing proposition, there are varying levels of access. One can have access to computational media through a cellular phone, in a browser’s console, a shared computer terminal in a library, or through the might of a multi-national company supporting the execution of your code. The level of access an transform the nature of how one interacts with the media.

This provides a starting point for articulating a bespoke educational model. One that is responsive to the needs of the students, and gets them involved in questioning the ways these tools express themselves in daily life.

We've seen how data can influence populations, algorthims accelerate human biases, and technologies help consolidate resources rather than resistribute them. As educators, we should be pushing against these tendencies.

We need to get students asking about the values that are reflected in the tools we use, and how that can be expressed in practice. 

## Exposing Algorithms 
Algorithms rule our social interactions when communication is mediated by machines. Facebook, Twitter, Instagram, and Gmail decide what gets seen, who is promoted, and was language is used in ur conversations. This is sometimes done with explicit results, like Facebook and Instagram barring nudity, and other times with suggestions like Gmail’s automatically generated “quick responses”. Posts are promoted by engagement and popularity. If there’s something disagreeable but not banned, it worms its way into the public space because people will react to the content.

Contemporary media art is nothing if not algorithmic in nature. Mainstays of the software art scene like Casey Reas are very much *all about the algorithims*. And this is good! This is a fundamental engagement with contemporary media art, particularly when dealing with interactive work which has an input,  process, and output. Learning how to create an algorithm is important. However, it's also important to understand how algorithms come to learn about the world. Exposing the limitations and boundaries of these tools can be a useful step in asking questions about algorithmic culture. 

It's easy to cede decisions to computational tools for a variety of reasons; a large one is the appearance of neutrality. If it’s on a computer and digital, it must be objective! The flaw in this assumption is that these tools are made by people, and our baises worm their way into the ways these express themselves.  

Adam Harvey's [CV Dazzle](https://ahprojects.com/cvdazzle/) and  [Hyperface](https://ahprojects.com/hyperface/) projects leverage computer vision algorithms in various ways, exposing the weaknesses and biases in a powerful, commonplace tool.

These projects thwart computer vision libraries from computationally identifying faces. While this exposes the functionality of the tools, it also opens up broader questions about privacy, surveillance, and analysis. CV Dazzle achieves this through makeup and hairstyling to make a face appear less than human. Hyperface does this by creating multiple false positives, overloading the system with false faces. This exploit leverages the expectations of the algorithm to negate its effectiveness.

Here, it’s apparent that knowledge of the algorithm is used for identifying the means though which we can subvert expectations. Knowing the tools is a starting point, but knowing the limitations and exploiting them opens the door for a different kind of critique that is more abotu culture than it is about technology.

## Infrastructure exploration
Parapharsing Susan Starr, “One person’s infrastructure is another’s job.” [5](5) The technological toolchain is phsycially made up of deep time, coming from the earth’s core, manifesting as materials we dig up and put into batteries, comprised of shipping lanes and data packets that help plan the movement of freight shipments across the world. Knowing the basics of electronic hardware is a good place to begin to understand the ways in which we are materially tied to the earth. [6](6)

A microcontroller is not just a small computer on a chip, it is the sum evolution of strip mining, cryptography and war, and the never-ending quest to make faster computational tools. The evolution of these from specialty devices designed for rocket guidance systems to art based platforms should not be covered up or obscured. It’s through these roots of media’s history that we can understand the present. 

Embedded systems like microcontrollers which enable the “internet of things” have also given rise to the network as a metaphor for how we understand and talk about these tools. In part, this is because computational devices tend to not operate isolated from each other. They are connected through infrastructure, the physical systems that enable them to act upon other forms of media. The network metaphor offers us a way to talk about these immaterial operations and potentially executable symbols as something that lives alongside the physical infrastructure. This metaphor, coupled with physical points of access, offer potential moments of exposure to the increasingly baroque systems of operation that support computation. 

The current vogue of internet connected devices is enabled by both the physical proliferation of financially inexpensive devices and “the cloud”; the nebulous entity that stores our information and retrieves our movie suggestions. Identifying the ways in which these infrastructures engender, consolidate and expand existing power structures can happen in this space.

For example, Evan Roth’s [Red Lines](http://p2p.redlines.network/) documents the points where undersea fiber optics lines come on shore. These locations mark places where boundaries are crossed and act as a physical reminder of the infrastructures that carry information around the world. The naming refers to the infrared light that transmits data as quickly as possible in the fiber, but also harkens back to the maps that marked underseas telegraph cables with red lines operated by the British. These marked conectiond from London to the empire's various military outposts. The paths the cables flow are the same. We reinforce existing structures as we add new layers to them. 

## interaction/machine learning
The primary differentiator between computational media and traditional media, its executability of it, requires multiple agents to become manifest. Traditional media was a consumption model, something was made by an agent, then consumed by another. With computational media, the dynamics between the two is shifting. Working with APIs and the transfer of information between machines is an entry point to conversatiosn about data, its use, and the ways it can be manipulated by us ans us by the data. 

Computational media relies on humans as a resource for generation and consumption, but also for interaction and information. The capacity of computational media changes and grows with accumulated data, power, resources, and research into its capabilities. Humanity is now a resource for the media itself; pressing buttons to reconfigure the systems while providing the content that feed the machine. The massive accumulation of data that is driving what we call “machine learning” is fully transforming humanity into a resource for computational media.

We train google’s autonomous car efforts with reCaptchas, identifying buses, bicycles, traffic lights and signs. We contribute to voice recognition with Amazon Echoes, Google homes and Apple’s Siri. These then retrain us based on the data they have received, moving towards a homogenized and stagnant environment, where all information is a generality brought forth through an algorithim trained on our behaviors where we try to please the machine to make them happy.

Stephanie Dinkin's [Conversations with Bina48](http://www.stephaniedinkins.com/conversations-with-bina48.html) examines how we can build a relationship with intellegent machines. An ongoing conversation between the artist and an antrophormic robot that presents as an elderly African-American woman running an AI that is designed to act as analogous to a human as possible. The conversations, which act as training material for the AI, have covered topics like "family, racism, faith, robot civil rights, loneliness, knowledge and Bina48’s concern for her robot friend that are treated more like lab rats than people." The conversations are humorous and engaging in a way that reveals some of the frustrations and limitations of engaging with machines that try to respond intellegently to human behaviors.

## data and access
In addition to being used as a training model for machines, data can also be leveraged as a tool for research and journalism. There is a growing awareness of how human bias leaks into computational tools. New organizations like [Data and Society](https://datasociety.net/) and the [AI Now Institute](https://ainowinstitute.org/), are finding new ways to engage in critical media through data. 

These social endeavors move beyond the “intersection of art an technology” and start to raise an awareness of community based and led research into the implications of contemporary technologies. 

Individuals like [Mimi Onuoha](http://mimionuoha.com/) also engage in this type of investigation. Her writings [on algorithmic violence](https://github.com/MimiOnuoha/On-Algorithmic-Violence) identify ways in which unequal access to information and computation reinforce the status quo, paving a path for capitalism to continue unabated by predictive policing to mobilize forces against those least able to defend themselves.

This last point truly extends beyond the screen and into the fabric of our lives. As we have integrated digital tools into all aspects of society, they have the potential to raise us up or pull us down. We need to acknowledge that the tools we use are loaded with political and social implications. They are not created with artists in mind, but they are accessiable. In that accessability, we must be mindful of how we engage with them. We need to engage in bottom-up methods[9](9) of working with contemporary tecnhologies that are not only-human centric, but also engaged in reflecting and examinging the ways in which these tools shape culture and society.

---

<a name = "1"></a> 1 This is also written as an bit of an aspirational call for myself, identifying work I admire, and ways I'd like to challenge myself. Recent works like [MAC Check](https://ennuigo.com/projects/MAC-Check/) and [Learning Solitude](https://www.instagram.com/learningsolitude/) are some recent attempts. 

<a name = "2"></a> 2 Socio-economics, race, and gender issues are all implicated here. 

<a name = "3"></a> 3 [IDM](http://idm.engineering.nyu.edu/)

<a name="4"></a> 4 It's that lovely old chestnut that "guns don't kill people, people kill people." This sidesteps 1) gus engender violence because they are an easy weapo and 2) it comepletly neglects any way to address human factors. Why not build the anti-gun, one that actively inhibits violence between people?

<a name="5"></a> 5 Star, Susan Leigh. “The Ethnography of Infrastructure.” The American Behavioral Scientist, vol. 43, no. 3, SAGE Publications Inc, Nov. 1999, pp. 377–91.

<a name="6"></a> 6 My own work has explored this materiality as well. [SBBOD](https://ennuigo.com/projects/SBBOD/) ties together the abstract work of a computer's processor to the physical labor involved in mining materials from the earth that are needed to manufature computers. 

<a name="7"></a> 7 Sam Lavigne’s [Training Poses](http://lav.io/training/) is another great example of training data that "trains us"

<a name="8"></a> 8 Also a shoutout to ProPublica's work on [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)

<a name="9"></a> 9  There’s a reason this is being posted on Github, where the text is available for anyone to fork and adapt, add on, or change. (I recognize the irony of discussing bottom-up approaches on a platform owned by Microsoft, but it's a place to start)
